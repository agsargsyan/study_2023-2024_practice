\chapter{Результаты}

Мною был написана программа, реализующая имитационную модель сети со следующей топологией:
\begin{itemize}
\item $N=20$ TCP-источников, N TCP-приёмников, двух маршрутизаторов R1 и R2 между источниками и приёмниками (N — не менее 20);
\item между TCP-источниками и первым маршрутизатором установлены дуплексные соединения с пропускной способностью 100 Мбит/с и задержкой 20 мс очередью типа DropTail;
\item между TCP-приёмниками и вторым маршрутизатором установлены дуплексные соединения с пропускной способностью 100 Мбит/с и задержкой 20 мс очередью типа DropTail;
\item между маршрутизаторами установлено симплексное соединение (R1–R2) с пропускной способностью 20 Мбит/с и задержкой 15 мс очередью типа RED,
размером буфера 300 пакетов; в обратную сторону — симплексное соединение (R2–R1) с пропускной способностью 15 Мбит/с и задержкой 20 мс очередью типа DropTail;
\item данные передаются по протоколу FTP поверх TCPReno;
\item параметры алгоритма RED: $q_{min}=75, q_{max}=150, q_w=0, 002, p_{max}=0.1$;
\item максимальный размер TCP-окна 32; размер передаваемого пакета 500 байт; время моделирования — не менее 20 единиц модельного времени.
\end{itemize}

Полная реализация программы приведена в разделе  \textbf{Приложения},  для вывода графиков была использована программа GNUPLOT.

Смоделировав сеть с указанными параметрами и запустив gnuplot скрипт, я получил следующий график(рис.~\ref{fig:3.1}).

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.6\linewidth]{image/queues_75-150_classic.eps}
  \caption{График длины очередей на линке(R0-R1)($q_{min}=75, q_{max}=150, q_w=0.002, p_{max}=0.1$,  TCP типа TCP/Reno)}
  \label{fig:3.1}
\end{figure}

Как мы видим из первого графика, в момент времени  $t=1 c$ достигается максимальные длины очереди 140000 пакетов и средней длины очереди 120000 пакетов, а при дальнейшем моделировании длина очереди варьируются от 0 до 70000 пакетов, а средняя очередь от 0 до 60000, наступает стационарное состояние. 

Для выявления влияния пороговых значений на длину очереди смоделировал сеть и вывел в одном графике длины средней очереди при разных пороговых значений, и при одинаковых остальных параметров (рис.~\ref{fig:3.2}).

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.6\linewidth]{image/av_queues_maxthresh.eps}
  \caption{График длины очоредей при разных порогов}
  \label{fig:3.2}
\end{figure}

Как видно из графика, уменьшение увелечение диапазона между $q_{min}$ и $q_{max}$ способствует увелечению длины очереди на линке.

Для сравнений различных модификаций смоделировали сеть, задав в качестве очереди RED, GRED, NLRED, RARED(рис.~\ref{fig:3.3},~\ref{fig:3.4},~\ref{fig:3.5},~\ref{fig:3.6}). 

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.6\linewidth]{image/av_queues_classic_gentle.eps}
  \caption{Средняя очередь RED и GRED при одинаковых условиях}
  \label{fig:3.3}
\end{figure}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.6\linewidth]{image/av_queues_3types.eps}
  \caption{Средние очереди RED, GRED, ARED при одинаковых условиях}
  \label{fig:3.4}
\end{figure}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.6\linewidth]{image/queues_3types.eps}
  \caption{Очереди RED, GRED, ARED при одинаковых условиях}
  \label{fig:3.5}
\end{figure}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.6\linewidth]{image/av_queues_classic_nonlinear.eps}
  \caption{Средние очереди RED, NLRED при одинаковых условиях}
  \label{fig:3.6}
\end{figure}

Различие между RARED с остальными модификациями легко объяснять его автоматическим выбором минимального и максимального пороговых величин. Средняя очередь при Gentle Red до стационарного состояния гораздо выше, что обьяснется его более мягким алгоритмом. Моделировние NLRED не показало никаких различий с классическим RED, что указывет на неработаспособность патча.  

Смоделировали сеть при разных TCP(Reno, Vegas и Newreno) (рис.~\ref{fig:3.7},~\ref{fig:3.8},~\ref{fig:3.9}). 

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.6\linewidth]{image/av_queues_tcp.eps}
  \caption{График длины очередей на линке(R0-R1) при разных TCP}
  \label{fig:3.7}
\end{figure}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.6\linewidth]{image/TCP_75-150_classic.eps}
  \caption{График размера TCP окна для всех источников(TCP типа TCP/Reno)}
  \label{fig:3.8}
\end{figure}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.6\linewidth]{image/TCP_vegas.eps}
  \caption{График размера TCP окна для всех источников(TCP типа TCP/Vegas)}
  \label{fig:3.9}
\end{figure}

Такое заметное отличие TCP/Vegas от TCP/Reno и TCP/Newreno объяснется тем, что он использует альтернативный подход к управлению очередьями. Вместо использования потери пакетов в качестве индикатора перегрузки сети, вместо этого он анализирует задержку пакетов в сети и использует данную информацию для определения, происходит ли перегрузка сети.




